2022-04-15 21:57:36,190 - train - INFO - kernel_extract_network(
  (encoder): kernel_generator(
    (basic_block): Sequential()
    (chain0): chain_process(
      (seq): Sequential(
        (0): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (2): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(27, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(81, 81, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (3): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(81, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(81, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(81, 243, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(81, 243, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(243, 243, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain1): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (2): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(27, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(81, 81, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain2): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain3): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (3): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain4): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (3): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (4): Sequential()
      )
    )
    (oneSizeConv): oneSizeConv(
      (CBR): convBlock(
        (conv): Conv2d(363, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (dropout): Dropout2d(p=0.5, inplace=False)
      )
    )
  )
  (decoder): classify_decoder(
    (CBR): convBlock(
      (conv): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
      (dropout): Dropout2d(p=0.5, inplace=False)
    )
    (MLP): MLP(
      (inp): Linear(in_features=127, out_features=64, bias=True)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): LeakyReLU(negative_slope=0.01)
      (hidden): Linear(in_features=64, out_features=50, bias=True)
      (bn2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): LeakyReLU(negative_slope=0.01)
      (sftmax): Softmax(dim=1)
    )
  )
)
2022-04-15 22:00:24,622 - trainer - INFO -     epoch          : 1
2022-04-15 22:00:24,688 - trainer - INFO -     loss           : 3.907985812739322
2022-04-15 22:00:24,689 - trainer - INFO -     accuracy       : 0.03472839615931721
2022-04-15 22:00:24,689 - trainer - INFO -     top_k_acc      : 0.09551698079658606
2022-04-15 22:00:24,689 - trainer - INFO -     val_loss       : 3.901625394821167
2022-04-15 22:00:24,689 - trainer - INFO -     val_accuracy   : 0.046875
2022-04-15 22:00:24,689 - trainer - INFO -     val_top_k_acc  : 0.10416666666666667
2022-04-15 22:00:25,421 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch1.pth ...
2022-04-15 22:00:25,596 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:02:05,349 - trainer - INFO -     epoch          : 2
2022-04-15 22:02:05,349 - trainer - INFO -     loss           : 3.8967005955545524
2022-04-15 22:02:05,350 - trainer - INFO -     accuracy       : 0.07230174253200569
2022-04-15 22:02:05,350 - trainer - INFO -     top_k_acc      : 0.14054165184921763
2022-04-15 22:02:05,350 - trainer - INFO -     val_loss       : 3.895906130472819
2022-04-15 22:02:05,350 - trainer - INFO -     val_accuracy   : 0.07161458333333333
2022-04-15 22:02:05,350 - trainer - INFO -     val_top_k_acc  : 0.21744791666666666
2022-04-15 22:02:08,046 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch2.pth ...
2022-04-15 22:02:08,186 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:03:21,421 - trainer - INFO -     epoch          : 3
2022-04-15 22:03:21,422 - trainer - INFO -     loss           : 3.886052420264796
2022-04-15 22:03:21,422 - trainer - INFO -     accuracy       : 0.09712837837837839
2022-04-15 22:03:21,422 - trainer - INFO -     top_k_acc      : 0.17748155227596019
2022-04-15 22:03:21,422 - trainer - INFO -     val_loss       : 3.88856569925944
2022-04-15 22:03:21,422 - trainer - INFO -     val_accuracy   : 0.06640625
2022-04-15 22:03:21,422 - trainer - INFO -     val_top_k_acc  : 0.13541666666666666
2022-04-15 22:03:21,573 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch3.pth ...
2022-04-15 22:03:21,719 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:04:35,018 - trainer - INFO -     epoch          : 4
2022-04-15 22:04:35,018 - trainer - INFO -     loss           : 3.879183530807495
2022-04-15 22:04:35,018 - trainer - INFO -     accuracy       : 0.10992509779516357
2022-04-15 22:04:35,019 - trainer - INFO -     top_k_acc      : 0.19745732574679942
2022-04-15 22:04:35,019 - trainer - INFO -     val_loss       : 3.87642240524292
2022-04-15 22:04:35,019 - trainer - INFO -     val_accuracy   : 0.15625
2022-04-15 22:04:35,019 - trainer - INFO -     val_top_k_acc  : 0.22786458333333334
2022-04-15 22:04:35,177 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch4.pth ...
2022-04-15 22:04:35,331 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:05:47,917 - trainer - INFO -     epoch          : 5
2022-04-15 22:05:47,918 - trainer - INFO -     loss           : 3.8711126980028654
2022-04-15 22:05:47,918 - trainer - INFO -     accuracy       : 0.11402027027027027
2022-04-15 22:05:47,918 - trainer - INFO -     top_k_acc      : 0.20648670874822192
2022-04-15 22:05:47,918 - trainer - INFO -     val_loss       : 3.8806559244791665
2022-04-15 22:05:47,918 - trainer - INFO -     val_accuracy   : 0.09244791666666667
2022-04-15 22:05:47,918 - trainer - INFO -     val_top_k_acc  : 0.23828125
2022-04-15 22:05:48,070 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch5.pth ...
2022-04-15 22:06:57,618 - trainer - INFO -     epoch          : 6
2022-04-15 22:06:57,619 - trainer - INFO -     loss           : 3.8664843032234595
2022-04-15 22:06:57,619 - trainer - INFO -     accuracy       : 0.12289407005689901
2022-04-15 22:06:57,619 - trainer - INFO -     top_k_acc      : 0.22272848506401136
2022-04-15 22:06:57,619 - trainer - INFO -     val_loss       : 3.875941038131714
2022-04-15 22:06:57,619 - trainer - INFO -     val_accuracy   : 0.16927083333333334
2022-04-15 22:06:57,619 - trainer - INFO -     val_top_k_acc  : 0.24088541666666666
2022-04-15 22:06:57,781 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch6.pth ...
2022-04-15 22:06:57,927 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:08:06,788 - trainer - INFO -     epoch          : 7
2022-04-15 22:08:06,788 - trainer - INFO -     loss           : 3.8587161616275183
2022-04-15 22:08:06,788 - trainer - INFO -     accuracy       : 0.1331570056899004
2022-04-15 22:08:06,788 - trainer - INFO -     top_k_acc      : 0.22663473506401136
2022-04-15 22:08:06,789 - trainer - INFO -     val_loss       : 3.8866345087687173
2022-04-15 22:08:06,789 - trainer - INFO -     val_accuracy   : 0.07421875
2022-04-15 22:08:06,789 - trainer - INFO -     val_top_k_acc  : 0.14973958333333334
2022-04-15 22:08:06,944 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch7.pth ...
2022-04-15 22:09:14,617 - trainer - INFO -     epoch          : 8
2022-04-15 22:09:14,617 - trainer - INFO -     loss           : 3.855214658536409
2022-04-15 22:09:14,618 - trainer - INFO -     accuracy       : 0.1309455014224751
2022-04-15 22:09:14,618 - trainer - INFO -     top_k_acc      : 0.2279683054765292
2022-04-15 22:09:14,618 - trainer - INFO -     val_loss       : 3.8821093241373696
2022-04-15 22:09:14,618 - trainer - INFO -     val_accuracy   : 0.09114583333333333
2022-04-15 22:09:14,618 - trainer - INFO -     val_top_k_acc  : 0.16276041666666666
2022-04-15 22:09:14,772 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch8.pth ...
2022-04-15 22:10:23,238 - trainer - INFO -     epoch          : 9
2022-04-15 22:10:23,239 - trainer - INFO -     loss           : 3.8467177968276176
2022-04-15 22:10:23,239 - trainer - INFO -     accuracy       : 0.13829680832147936
2022-04-15 22:10:23,239 - trainer - INFO -     top_k_acc      : 0.23693100995732577
2022-04-15 22:10:23,239 - trainer - INFO -     val_loss       : 3.871311982472738
2022-04-15 22:10:23,239 - trainer - INFO -     val_accuracy   : 0.17838541666666666
2022-04-15 22:10:23,240 - trainer - INFO -     val_top_k_acc  : 0.3372395833333333
2022-04-15 22:10:23,409 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch9.pth ...
2022-04-15 22:10:23,558 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:11:29,844 - trainer - INFO -     epoch          : 10
2022-04-15 22:11:29,844 - trainer - INFO -     loss           : 3.842516773625424
2022-04-15 22:11:29,844 - trainer - INFO -     accuracy       : 0.15017114153627312
2022-04-15 22:11:29,844 - trainer - INFO -     top_k_acc      : 0.25267825391180654
2022-04-15 22:11:29,844 - trainer - INFO -     val_loss       : 3.821648915608724
2022-04-15 22:11:29,844 - trainer - INFO -     val_accuracy   : 0.17838541666666666
2022-04-15 22:11:29,844 - trainer - INFO -     val_top_k_acc  : 0.3255208333333333
2022-04-15 22:11:30,006 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch10.pth ...
2022-04-15 22:11:30,159 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:12:37,886 - trainer - INFO -     epoch          : 11
2022-04-15 22:12:37,887 - trainer - INFO -     loss           : 3.8390120581576697
2022-04-15 22:12:37,887 - trainer - INFO -     accuracy       : 0.14919318990042674
2022-04-15 22:12:37,887 - trainer - INFO -     top_k_acc      : 0.2504667496443812
2022-04-15 22:12:37,887 - trainer - INFO -     val_loss       : 3.8314735889434814
2022-04-15 22:12:37,887 - trainer - INFO -     val_accuracy   : 0.265625
2022-04-15 22:12:37,887 - trainer - INFO -     val_top_k_acc  : 0.4270833333333333
2022-04-15 22:12:38,059 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch11.pth ...
2022-04-15 22:13:48,114 - trainer - INFO -     epoch          : 12
2022-04-15 22:13:48,115 - trainer - INFO -     loss           : 3.834063090776142
2022-04-15 22:13:48,115 - trainer - INFO -     accuracy       : 0.16166762980085347
2022-04-15 22:13:48,115 - trainer - INFO -     top_k_acc      : 0.26607508001422475
2022-04-15 22:13:48,115 - trainer - INFO -     val_loss       : 3.8866991996765137
2022-04-15 22:13:48,115 - trainer - INFO -     val_accuracy   : 0.07942708333333333
2022-04-15 22:13:48,115 - trainer - INFO -     val_top_k_acc  : 0.15494791666666666
2022-04-15 22:13:48,274 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch12.pth ...
2022-04-15 22:14:56,276 - trainer - INFO -     epoch          : 13
2022-04-15 22:14:56,276 - trainer - INFO -     loss           : 3.8234302621138725
2022-04-15 22:14:56,276 - trainer - INFO -     accuracy       : 0.17194723506401138
2022-04-15 22:14:56,277 - trainer - INFO -     top_k_acc      : 0.28002200391180654
2022-04-15 22:14:56,277 - trainer - INFO -     val_loss       : 3.8696632385253906
2022-04-15 22:14:56,277 - trainer - INFO -     val_accuracy   : 0.09765625
2022-04-15 22:14:56,277 - trainer - INFO -     val_top_k_acc  : 0.3372395833333333
2022-04-15 22:14:56,437 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch13.pth ...
2022-04-15 22:16:04,173 - trainer - INFO -     epoch          : 14
2022-04-15 22:16:04,173 - trainer - INFO -     loss           : 3.8247747672231576
2022-04-15 22:16:04,174 - trainer - INFO -     accuracy       : 0.165862820056899
2022-04-15 22:16:04,174 - trainer - INFO -     top_k_acc      : 0.2776549164295875
2022-04-15 22:16:04,174 - trainer - INFO -     val_loss       : 3.859258015950521
2022-04-15 22:16:04,174 - trainer - INFO -     val_accuracy   : 0.10807291666666667
2022-04-15 22:16:04,174 - trainer - INFO -     val_top_k_acc  : 0.2682291666666667
2022-04-15 22:16:04,328 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch14.pth ...
2022-04-15 22:17:11,748 - trainer - INFO -     epoch          : 15
2022-04-15 22:17:11,748 - trainer - INFO -     loss           : 3.8163146345238936
2022-04-15 22:17:11,748 - trainer - INFO -     accuracy       : 0.18272137268847796
2022-04-15 22:17:11,748 - trainer - INFO -     top_k_acc      : 0.2856229996443812
2022-04-15 22:17:11,748 - trainer - INFO -     val_loss       : 3.8607988357543945
2022-04-15 22:17:11,748 - trainer - INFO -     val_accuracy   : 0.19010416666666666
2022-04-15 22:17:11,748 - trainer - INFO -     val_top_k_acc  : 0.3450520833333333
2022-04-15 22:17:11,904 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch15.pth ...
2022-04-15 22:18:19,778 - trainer - INFO -     epoch          : 16
2022-04-15 22:18:19,779 - trainer - INFO -     loss           : 3.805784777591103
2022-04-15 22:18:19,779 - trainer - INFO -     accuracy       : 0.19216193990042674
2022-04-15 22:18:19,779 - trainer - INFO -     top_k_acc      : 0.2963471283783784
2022-04-15 22:18:19,779 - trainer - INFO -     val_loss       : 3.8612926801045737
2022-04-15 22:18:19,779 - trainer - INFO -     val_accuracy   : 0.12369791666666667
2022-04-15 22:18:19,779 - trainer - INFO -     val_top_k_acc  : 0.18359375
2022-04-15 22:18:19,934 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch16.pth ...
2022-04-15 22:19:27,946 - trainer - INFO -     epoch          : 17
2022-04-15 22:19:27,947 - trainer - INFO -     loss           : 3.797242653997321
2022-04-15 22:19:27,947 - trainer - INFO -     accuracy       : 0.20244154516358462
2022-04-15 22:19:27,947 - trainer - INFO -     top_k_acc      : 0.30724350995732574
2022-04-15 22:19:27,947 - trainer - INFO -     val_loss       : 3.8525048096974692
2022-04-15 22:19:27,947 - trainer - INFO -     val_accuracy   : 0.12369791666666667
2022-04-15 22:19:27,947 - trainer - INFO -     val_top_k_acc  : 0.2890625
2022-04-15 22:19:28,101 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch17.pth ...
2022-04-15 22:20:33,017 - trainer - INFO -     epoch          : 18
2022-04-15 22:20:33,017 - trainer - INFO -     loss           : 3.784489217557405
2022-04-15 22:20:33,018 - trainer - INFO -     accuracy       : 0.22068923364153628
2022-04-15 22:20:33,018 - trainer - INFO -     top_k_acc      : 0.3298086326458037
2022-04-15 22:20:33,018 - trainer - INFO -     val_loss       : 3.827731211980184
2022-04-15 22:20:33,018 - trainer - INFO -     val_accuracy   : 0.20703125
2022-04-15 22:20:33,018 - trainer - INFO -     val_top_k_acc  : 0.3645833333333333
2022-04-15 22:20:33,169 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch18.pth ...
2022-04-15 22:21:40,580 - trainer - INFO -     epoch          : 19
2022-04-15 22:21:40,581 - trainer - INFO -     loss           : 3.7662650409497713
2022-04-15 22:21:40,581 - trainer - INFO -     accuracy       : 0.24971661628734
2022-04-15 22:21:40,582 - trainer - INFO -     top_k_acc      : 0.3573802009246088
2022-04-15 22:21:40,582 - trainer - INFO -     val_loss       : 3.7596027851104736
2022-04-15 22:21:40,582 - trainer - INFO -     val_accuracy   : 0.23567708333333334
2022-04-15 22:21:40,582 - trainer - INFO -     val_top_k_acc  : 0.390625
2022-04-15 22:21:40,736 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch19.pth ...
2022-04-15 22:21:40,879 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:22:47,969 - trainer - INFO -     epoch          : 20
2022-04-15 22:22:47,969 - trainer - INFO -     loss           : 3.7618320113734196
2022-04-15 22:22:47,970 - trainer - INFO -     accuracy       : 0.2494387891180654
2022-04-15 22:22:47,970 - trainer - INFO -     top_k_acc      : 0.3538462393314367
2022-04-15 22:22:47,970 - trainer - INFO -     val_loss       : 3.8231953779856362
2022-04-15 22:22:47,970 - trainer - INFO -     val_accuracy   : 0.2552083333333333
2022-04-15 22:22:47,970 - trainer - INFO -     val_top_k_acc  : 0.3190104166666667
2022-04-15 22:22:48,127 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch20.pth ...
2022-04-15 22:23:55,574 - trainer - INFO -     epoch          : 21
2022-04-15 22:23:55,574 - trainer - INFO -     loss           : 3.743114333403738
2022-04-15 22:23:55,575 - trainer - INFO -     accuracy       : 0.2655083125889047
2022-04-15 22:23:55,575 - trainer - INFO -     top_k_acc      : 0.3722995199146515
2022-04-15 22:23:55,575 - trainer - INFO -     val_loss       : 3.7362945874532065
2022-04-15 22:23:55,575 - trainer - INFO -     val_accuracy   : 0.3346354166666667
2022-04-15 22:23:55,575 - trainer - INFO -     val_top_k_acc  : 0.4166666666666667
2022-04-15 22:23:55,726 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch21.pth ...
2022-04-15 22:23:55,868 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:25:03,810 - trainer - INFO -     epoch          : 22
2022-04-15 22:25:03,810 - trainer - INFO -     loss           : 3.72750755360252
2022-04-15 22:25:03,810 - trainer - INFO -     accuracy       : 0.27839393669985774
2022-04-15 22:25:03,810 - trainer - INFO -     top_k_acc      : 0.3823235241820768
2022-04-15 22:25:03,810 - trainer - INFO -     val_loss       : 3.775092363357544
2022-04-15 22:25:03,810 - trainer - INFO -     val_accuracy   : 0.2682291666666667
2022-04-15 22:25:03,811 - trainer - INFO -     val_top_k_acc  : 0.5091145833333334
2022-04-15 22:25:03,968 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch22.pth ...
2022-04-15 22:26:10,522 - trainer - INFO -     epoch          : 23
2022-04-15 22:26:10,523 - trainer - INFO -     loss           : 3.7094331666042932
2022-04-15 22:26:10,523 - trainer - INFO -     accuracy       : 0.29424119843527735
2022-04-15 22:26:10,523 - trainer - INFO -     top_k_acc      : 0.3926698079658606
2022-04-15 22:26:10,524 - trainer - INFO -     val_loss       : 3.659471352895101
2022-04-15 22:26:10,524 - trainer - INFO -     val_accuracy   : 0.3645833333333333
2022-04-15 22:26:10,524 - trainer - INFO -     val_top_k_acc  : 0.4296875
2022-04-15 22:26:10,763 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch23.pth ...
2022-04-15 22:26:10,907 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:27:18,419 - trainer - INFO -     epoch          : 24
2022-04-15 22:27:18,419 - trainer - INFO -     loss           : 3.705572153392591
2022-04-15 22:27:18,419 - trainer - INFO -     accuracy       : 0.29984219416785207
2022-04-15 22:27:18,420 - trainer - INFO -     top_k_acc      : 0.38925809032716924
2022-04-15 22:27:18,420 - trainer - INFO -     val_loss       : 3.7333672841389975
2022-04-15 22:27:18,420 - trainer - INFO -     val_accuracy   : 0.2825520833333333
2022-04-15 22:27:18,420 - trainer - INFO -     val_top_k_acc  : 0.3450520833333333
2022-04-15 22:27:18,581 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch24.pth ...
2022-04-15 22:28:26,318 - trainer - INFO -     epoch          : 25
2022-04-15 22:28:26,318 - trainer - INFO -     loss           : 3.6900479793548584
2022-04-15 22:28:26,318 - trainer - INFO -     accuracy       : 0.31211104196301565
2022-04-15 22:28:26,318 - trainer - INFO -     top_k_acc      : 0.41314567034139404
2022-04-15 22:28:26,318 - trainer - INFO -     val_loss       : 3.558227221171061
2022-04-15 22:28:26,318 - trainer - INFO -     val_accuracy   : 0.44921875
2022-04-15 22:28:26,318 - trainer - INFO -     val_top_k_acc  : 0.5286458333333334
2022-04-15 22:28:26,473 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch25.pth ...
2022-04-15 22:28:26,627 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:29:34,159 - trainer - INFO -     epoch          : 26
2022-04-15 22:29:34,160 - trainer - INFO -     loss           : 3.6829752922058105
2022-04-15 22:29:34,160 - trainer - INFO -     accuracy       : 0.32365753911806544
2022-04-15 22:29:34,160 - trainer - INFO -     top_k_acc      : 0.4175631223328592
2022-04-15 22:29:34,160 - trainer - INFO -     val_loss       : 3.698181390762329
2022-04-15 22:29:34,160 - trainer - INFO -     val_accuracy   : 0.2994791666666667
2022-04-15 22:29:34,160 - trainer - INFO -     val_top_k_acc  : 0.3841145833333333
2022-04-15 22:29:34,313 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch26.pth ...
2022-04-15 22:30:43,179 - trainer - INFO -     epoch          : 27
2022-04-15 22:30:43,180 - trainer - INFO -     loss           : 3.667671429483514
2022-04-15 22:30:43,180 - trainer - INFO -     accuracy       : 0.3385824146514936
2022-04-15 22:30:43,180 - trainer - INFO -     top_k_acc      : 0.43536628733997157
2022-04-15 22:30:43,180 - trainer - INFO -     val_loss       : 3.6757373809814453
2022-04-15 22:30:43,180 - trainer - INFO -     val_accuracy   : 0.3072916666666667
2022-04-15 22:30:43,180 - trainer - INFO -     val_top_k_acc  : 0.4661458333333333
2022-04-15 22:30:43,335 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch27.pth ...
2022-04-15 22:31:51,107 - trainer - INFO -     epoch          : 28
2022-04-15 22:31:51,107 - trainer - INFO -     loss           : 3.665793720044588
2022-04-15 22:31:51,108 - trainer - INFO -     accuracy       : 0.3320868154338549
2022-04-15 22:31:51,108 - trainer - INFO -     top_k_acc      : 0.4401115753911806
2022-04-15 22:31:51,108 - trainer - INFO -     val_loss       : 3.63196595509847
2022-04-15 22:31:51,108 - trainer - INFO -     val_accuracy   : 0.3997395833333333
2022-04-15 22:31:51,108 - trainer - INFO -     val_top_k_acc  : 0.4609375
2022-04-15 22:31:51,269 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch28.pth ...
2022-04-15 22:32:59,968 - trainer - INFO -     epoch          : 29
2022-04-15 22:32:59,969 - trainer - INFO -     loss           : 3.6550786746175667
2022-04-15 22:32:59,969 - trainer - INFO -     accuracy       : 0.3478673986486487
2022-04-15 22:32:59,969 - trainer - INFO -     top_k_acc      : 0.44487353307254623
2022-04-15 22:32:59,969 - trainer - INFO -     val_loss       : 3.590649127960205
2022-04-15 22:32:59,969 - trainer - INFO -     val_accuracy   : 0.3971354166666667
2022-04-15 22:32:59,969 - trainer - INFO -     val_top_k_acc  : 0.4674479166666667
2022-04-15 22:33:00,122 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch29.pth ...
2022-04-15 22:34:07,987 - trainer - INFO -     epoch          : 30
2022-04-15 22:34:07,987 - trainer - INFO -     loss           : 3.641947018472772
2022-04-15 22:34:07,987 - trainer - INFO -     accuracy       : 0.367776493598862
2022-04-15 22:34:07,987 - trainer - INFO -     top_k_acc      : 0.46985575213371267
2022-04-15 22:34:07,987 - trainer - INFO -     val_loss       : 3.575444539388021
2022-04-15 22:34:07,987 - trainer - INFO -     val_accuracy   : 0.4088541666666667
2022-04-15 22:34:07,988 - trainer - INFO -     val_top_k_acc  : 0.4817708333333333
2022-04-15 22:34:08,146 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch30.pth ...
2022-04-15 22:35:16,464 - trainer - INFO -     epoch          : 31
2022-04-15 22:35:16,464 - trainer - INFO -     loss           : 3.6346790037657084
2022-04-15 22:35:16,464 - trainer - INFO -     accuracy       : 0.3721272670697013
2022-04-15 22:35:16,465 - trainer - INFO -     top_k_acc      : 0.466666296230441
2022-04-15 22:35:16,465 - trainer - INFO -     val_loss       : 3.693425258000692
2022-04-15 22:35:16,465 - trainer - INFO -     val_accuracy   : 0.3268229166666667
2022-04-15 22:35:16,465 - trainer - INFO -     val_top_k_acc  : 0.5625
2022-04-15 22:35:16,624 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch31.pth ...
2022-04-15 22:36:23,186 - trainer - INFO -     epoch          : 32
2022-04-15 22:36:23,186 - trainer - INFO -     loss           : 3.6272034143146716
2022-04-15 22:36:23,186 - trainer - INFO -     accuracy       : 0.3798175231152205
2022-04-15 22:36:23,186 - trainer - INFO -     top_k_acc      : 0.4769292318634424
2022-04-15 22:36:23,187 - trainer - INFO -     val_loss       : 3.714898109436035
2022-04-15 22:36:23,187 - trainer - INFO -     val_accuracy   : 0.2643229166666667
2022-04-15 22:36:23,187 - trainer - INFO -     val_top_k_acc  : 0.4140625
2022-04-15 22:36:23,341 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch32.pth ...
2022-04-15 22:37:31,000 - trainer - INFO -     epoch          : 33
2022-04-15 22:37:31,001 - trainer - INFO -     loss           : 3.61562863149141
2022-04-15 22:37:31,001 - trainer - INFO -     accuracy       : 0.3883690433854908
2022-04-15 22:37:31,001 - trainer - INFO -     top_k_acc      : 0.48025204480796585
2022-04-15 22:37:31,001 - trainer - INFO -     val_loss       : 3.638364315032959
2022-04-15 22:37:31,001 - trainer - INFO -     val_accuracy   : 0.3359375
2022-04-15 22:37:31,001 - trainer - INFO -     val_top_k_acc  : 0.4114583333333333
2022-04-15 22:37:31,164 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch33.pth ...
2022-04-15 22:38:38,091 - trainer - INFO -     epoch          : 34
2022-04-15 22:38:38,092 - trainer - INFO -     loss           : 3.60278142125983
2022-04-15 22:38:38,092 - trainer - INFO -     accuracy       : 0.40068790007112376
2022-04-15 22:38:38,092 - trainer - INFO -     top_k_acc      : 0.49029271870554764
2022-04-15 22:38:38,092 - trainer - INFO -     val_loss       : 3.6190641721089682
2022-04-15 22:38:38,092 - trainer - INFO -     val_accuracy   : 0.3567708333333333
2022-04-15 22:38:38,092 - trainer - INFO -     val_top_k_acc  : 0.4140625
2022-04-15 22:38:38,244 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch34.pth ...
2022-04-15 22:39:45,643 - trainer - INFO -     epoch          : 35
2022-04-15 22:39:45,643 - trainer - INFO -     loss           : 3.5912311830018697
2022-04-15 22:39:45,643 - trainer - INFO -     accuracy       : 0.4118787784495021
2022-04-15 22:39:45,643 - trainer - INFO -     top_k_acc      : 0.4983997155049787
2022-04-15 22:39:45,643 - trainer - INFO -     val_loss       : 3.5678293704986572
2022-04-15 22:39:45,643 - trainer - INFO -     val_accuracy   : 0.4296875
2022-04-15 22:39:45,643 - trainer - INFO -     val_top_k_acc  : 0.5
2022-04-15 22:39:45,797 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch35.pth ...
2022-04-15 22:40:54,096 - trainer - INFO -     epoch          : 36
2022-04-15 22:40:54,096 - trainer - INFO -     loss           : 3.5859992002186023
2022-04-15 22:40:54,096 - trainer - INFO -     accuracy       : 0.41876333570412516
2022-04-15 22:40:54,096 - trainer - INFO -     top_k_acc      : 0.5042563122332858
2022-04-15 22:40:54,096 - trainer - INFO -     val_loss       : 3.5358359813690186
2022-04-15 22:40:54,096 - trainer - INFO -     val_accuracy   : 0.4388020833333333
2022-04-15 22:40:54,097 - trainer - INFO -     val_top_k_acc  : 0.5794270833333334
2022-04-15 22:40:54,252 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch36.pth ...
2022-04-15 22:40:54,399 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:42:03,863 - trainer - INFO -     epoch          : 37
2022-04-15 22:42:03,864 - trainer - INFO -     loss           : 3.5836925757558724
2022-04-15 22:42:03,864 - trainer - INFO -     accuracy       : 0.41691300675675674
2022-04-15 22:42:03,864 - trainer - INFO -     top_k_acc      : 0.5093794452347084
2022-04-15 22:42:03,864 - trainer - INFO -     val_loss       : 3.69709046681722
2022-04-15 22:42:03,864 - trainer - INFO -     val_accuracy   : 0.2721354166666667
2022-04-15 22:42:03,864 - trainer - INFO -     val_top_k_acc  : 0.3411458333333333
2022-04-15 22:42:04,017 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch37.pth ...
2022-04-15 22:43:11,686 - trainer - INFO -     epoch          : 38
2022-04-15 22:43:11,686 - trainer - INFO -     loss           : 3.5747891225312887
2022-04-15 22:43:11,686 - trainer - INFO -     accuracy       : 0.4196190433854908
2022-04-15 22:43:11,686 - trainer - INFO -     top_k_acc      : 0.5099962215504978
2022-04-15 22:43:11,686 - trainer - INFO -     val_loss       : 3.647120396296183
2022-04-15 22:43:11,686 - trainer - INFO -     val_accuracy   : 0.3515625
2022-04-15 22:43:11,687 - trainer - INFO -     val_top_k_acc  : 0.5026041666666666
2022-04-15 22:43:11,849 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch38.pth ...
2022-04-15 22:44:18,716 - trainer - INFO -     epoch          : 39
2022-04-15 22:44:18,716 - trainer - INFO -     loss           : 3.560722175397371
2022-04-15 22:44:18,716 - trainer - INFO -     accuracy       : 0.4435899715504979
2022-04-15 22:44:18,716 - trainer - INFO -     top_k_acc      : 0.5300775693456615
2022-04-15 22:44:18,716 - trainer - INFO -     val_loss       : 3.60929012298584
2022-04-15 22:44:18,716 - trainer - INFO -     val_accuracy   : 0.36328125
2022-04-15 22:44:18,717 - trainer - INFO -     val_top_k_acc  : 0.4309895833333333
2022-04-15 22:44:18,873 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch39.pth ...
2022-04-15 22:45:27,596 - trainer - INFO -     epoch          : 40
2022-04-15 22:45:27,597 - trainer - INFO -     loss           : 3.5560250282287598
2022-04-15 22:45:27,597 - trainer - INFO -     accuracy       : 0.44072835170697006
2022-04-15 22:45:27,597 - trainer - INFO -     top_k_acc      : 0.5341227329302987
2022-04-15 22:45:27,597 - trainer - INFO -     val_loss       : 3.5395635763804116
2022-04-15 22:45:27,598 - trainer - INFO -     val_accuracy   : 0.4518229166666667
2022-04-15 22:45:27,598 - trainer - INFO -     val_top_k_acc  : 0.5989583333333334
2022-04-15 22:45:27,753 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch40.pth ...
2022-04-15 22:46:35,500 - trainer - INFO -     epoch          : 41
2022-04-15 22:46:35,501 - trainer - INFO -     loss           : 3.553355442850213
2022-04-15 22:46:35,501 - trainer - INFO -     accuracy       : 0.4376278004978663
2022-04-15 22:46:35,501 - trainer - INFO -     top_k_acc      : 0.52372088371266
2022-04-15 22:46:35,501 - trainer - INFO -     val_loss       : 3.4521280924479165
2022-04-15 22:46:35,501 - trainer - INFO -     val_accuracy   : 0.5208333333333334
2022-04-15 22:46:35,501 - trainer - INFO -     val_top_k_acc  : 0.5911458333333334
2022-04-15 22:46:35,656 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch41.pth ...
2022-04-15 22:46:35,802 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:47:43,320 - trainer - INFO -     epoch          : 42
2022-04-15 22:47:43,320 - trainer - INFO -     loss           : 3.5531298110359595
2022-04-15 22:47:43,320 - trainer - INFO -     accuracy       : 0.4409839527027027
2022-04-15 22:47:43,320 - trainer - INFO -     top_k_acc      : 0.5327836059743954
2022-04-15 22:47:43,320 - trainer - INFO -     val_loss       : 3.673112471898397
2022-04-15 22:47:43,320 - trainer - INFO -     val_accuracy   : 0.2838541666666667
2022-04-15 22:47:43,320 - trainer - INFO -     val_top_k_acc  : 0.3580729166666667
2022-04-15 22:47:43,476 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch42.pth ...
2022-04-15 22:48:51,878 - trainer - INFO -     epoch          : 43
2022-04-15 22:48:51,878 - trainer - INFO -     loss           : 3.544915563181827
2022-04-15 22:48:51,878 - trainer - INFO -     accuracy       : 0.4527193723328592
2022-04-15 22:48:51,878 - trainer - INFO -     top_k_acc      : 0.5306054409672831
2022-04-15 22:48:51,878 - trainer - INFO -     val_loss       : 3.439317305882772
2022-04-15 22:48:51,878 - trainer - INFO -     val_accuracy   : 0.53515625
2022-04-15 22:48:51,878 - trainer - INFO -     val_top_k_acc  : 0.60546875
2022-04-15 22:48:52,034 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch43.pth ...
2022-04-15 22:48:52,188 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:50:00,549 - trainer - INFO -     epoch          : 44
2022-04-15 22:50:00,549 - trainer - INFO -     loss           : 3.5358223915100098
2022-04-15 22:50:00,549 - trainer - INFO -     accuracy       : 0.4586482041251778
2022-04-15 22:50:00,550 - trainer - INFO -     top_k_acc      : 0.543885579658606
2022-04-15 22:50:00,550 - trainer - INFO -     val_loss       : 3.5947559674580893
2022-04-15 22:50:00,550 - trainer - INFO -     val_accuracy   : 0.3776041666666667
2022-04-15 22:50:00,550 - trainer - INFO -     val_top_k_acc  : 0.44140625
2022-04-15 22:50:00,706 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch44.pth ...
2022-04-15 22:51:08,754 - trainer - INFO -     epoch          : 45
2022-04-15 22:51:08,754 - trainer - INFO -     loss           : 3.5299308927435624
2022-04-15 22:51:08,754 - trainer - INFO -     accuracy       : 0.45970950391180654
2022-04-15 22:51:08,755 - trainer - INFO -     top_k_acc      : 0.5406461148648648
2022-04-15 22:51:08,755 - trainer - INFO -     val_loss       : 3.57651424407959
2022-04-15 22:51:08,755 - trainer - INFO -     val_accuracy   : 0.37890625
2022-04-15 22:51:08,755 - trainer - INFO -     val_top_k_acc  : 0.5325520833333334
2022-04-15 22:51:08,923 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch45.pth ...
2022-04-15 22:52:15,255 - trainer - INFO -     epoch          : 46
2022-04-15 22:52:15,256 - trainer - INFO -     loss           : 3.525794694298192
2022-04-15 22:52:15,256 - trainer - INFO -     accuracy       : 0.46414918207681366
2022-04-15 22:52:15,256 - trainer - INFO -     top_k_acc      : 0.554131845661451
2022-04-15 22:52:15,256 - trainer - INFO -     val_loss       : 3.426186958948771
2022-04-15 22:52:15,256 - trainer - INFO -     val_accuracy   : 0.5481770833333334
2022-04-15 22:52:15,256 - trainer - INFO -     val_top_k_acc  : 0.6119791666666666
2022-04-15 22:52:15,412 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch46.pth ...
2022-04-15 22:52:15,558 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 22:53:23,930 - trainer - INFO -     epoch          : 47
2022-04-15 22:53:23,930 - trainer - INFO -     loss           : 3.52776258870175
2022-04-15 22:53:23,930 - trainer - INFO -     accuracy       : 0.4631712304409673
2022-04-15 22:53:23,930 - trainer - INFO -     top_k_acc      : 0.5570268047652916
2022-04-15 22:53:23,931 - trainer - INFO -     val_loss       : 3.6337258021036782
2022-04-15 22:53:23,931 - trainer - INFO -     val_accuracy   : 0.3893229166666667
2022-04-15 22:53:23,931 - trainer - INFO -     val_top_k_acc  : 0.53515625
2022-04-15 22:53:24,082 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch47.pth ...
2022-04-15 22:54:31,575 - trainer - INFO -     epoch          : 48
2022-04-15 22:54:31,576 - trainer - INFO -     loss           : 3.521898570813631
2022-04-15 22:54:31,576 - trainer - INFO -     accuracy       : 0.4703669541251778
2022-04-15 22:54:31,576 - trainer - INFO -     top_k_acc      : 0.5634334992887624
2022-04-15 22:54:31,576 - trainer - INFO -     val_loss       : 3.5034032662709556
2022-04-15 22:54:31,576 - trainer - INFO -     val_accuracy   : 0.4674479166666667
2022-04-15 22:54:31,576 - trainer - INFO -     val_top_k_acc  : 0.625
2022-04-15 22:54:31,731 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch48.pth ...
2022-04-15 22:55:40,079 - trainer - INFO -     epoch          : 49
2022-04-15 22:55:40,080 - trainer - INFO -     loss           : 3.507371237403468
2022-04-15 22:55:40,080 - trainer - INFO -     accuracy       : 0.4883923808677098
2022-04-15 22:55:40,080 - trainer - INFO -     top_k_acc      : 0.5685399626600285
2022-04-15 22:55:40,080 - trainer - INFO -     val_loss       : 3.574774424235026
2022-04-15 22:55:40,080 - trainer - INFO -     val_accuracy   : 0.3971354166666667
2022-04-15 22:55:40,080 - trainer - INFO -     val_top_k_acc  : 0.5494791666666666
2022-04-15 22:55:40,244 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch49.pth ...
2022-04-15 22:56:48,516 - trainer - INFO -     epoch          : 50
2022-04-15 22:56:48,516 - trainer - INFO -     loss           : 3.5043181620146098
2022-04-15 22:56:48,517 - trainer - INFO -     accuracy       : 0.4885813033428165
2022-04-15 22:56:48,517 - trainer - INFO -     top_k_acc      : 0.578169452347084
2022-04-15 22:56:48,517 - trainer - INFO -     val_loss       : 3.5426553885142007
2022-04-15 22:56:48,517 - trainer - INFO -     val_accuracy   : 0.4791666666666667
2022-04-15 22:56:48,517 - trainer - INFO -     val_top_k_acc  : 0.5390625
2022-04-15 22:56:48,670 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch50.pth ...
2022-04-15 22:57:57,223 - trainer - INFO -     epoch          : 51
2022-04-15 22:57:57,224 - trainer - INFO -     loss           : 3.4968042750107613
2022-04-15 22:57:57,224 - trainer - INFO -     accuracy       : 0.49329325213371267
2022-04-15 22:57:57,224 - trainer - INFO -     top_k_acc      : 0.579336326458037
2022-04-15 22:57:57,224 - trainer - INFO -     val_loss       : 3.5728108088175454
2022-04-15 22:57:57,224 - trainer - INFO -     val_accuracy   : 0.3997395833333333
2022-04-15 22:57:57,224 - trainer - INFO -     val_top_k_acc  : 0.4622395833333333
2022-04-15 22:57:57,393 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch51.pth ...
2022-04-15 22:59:04,432 - trainer - INFO -     epoch          : 52
2022-04-15 22:59:04,432 - trainer - INFO -     loss           : 3.4951083660125732
2022-04-15 22:59:04,432 - trainer - INFO -     accuracy       : 0.49726618065433853
2022-04-15 22:59:04,433 - trainer - INFO -     top_k_acc      : 0.5808588193456615
2022-04-15 22:59:04,433 - trainer - INFO -     val_loss       : 3.4880226453145347
2022-04-15 22:59:04,433 - trainer - INFO -     val_accuracy   : 0.4830729166666667
2022-04-15 22:59:04,433 - trainer - INFO -     val_top_k_acc  : 0.55078125
2022-04-15 22:59:04,587 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch52.pth ...
2022-04-15 23:00:12,422 - trainer - INFO -     epoch          : 53
2022-04-15 23:00:12,422 - trainer - INFO -     loss           : 3.493648127505654
2022-04-15 23:00:12,422 - trainer - INFO -     accuracy       : 0.4944045608108108
2022-04-15 23:00:12,423 - trainer - INFO -     top_k_acc      : 0.580242043029872
2022-04-15 23:00:12,423 - trainer - INFO -     val_loss       : 3.520462989807129
2022-04-15 23:00:12,423 - trainer - INFO -     val_accuracy   : 0.4817708333333333
2022-04-15 23:00:12,423 - trainer - INFO -     val_top_k_acc  : 0.5403645833333334
2022-04-15 23:00:12,579 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch53.pth ...
2022-04-15 23:01:20,266 - trainer - INFO -     epoch          : 54
2022-04-15 23:01:20,267 - trainer - INFO -     loss           : 3.4930068819146407
2022-04-15 23:01:20,267 - trainer - INFO -     accuracy       : 0.4949713282361308
2022-04-15 23:01:20,267 - trainer - INFO -     top_k_acc      : 0.5800364509246089
2022-04-15 23:01:20,267 - trainer - INFO -     val_loss       : 3.559723377227783
2022-04-15 23:01:20,267 - trainer - INFO -     val_accuracy   : 0.4075520833333333
2022-04-15 23:01:20,267 - trainer - INFO -     val_top_k_acc  : 0.5481770833333334
2022-04-15 23:01:20,424 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch54.pth ...
2022-04-15 23:02:27,424 - trainer - INFO -     epoch          : 55
2022-04-15 23:02:27,425 - trainer - INFO -     loss           : 3.4946549064234684
2022-04-15 23:02:27,425 - trainer - INFO -     accuracy       : 0.49279316322901845
2022-04-15 23:02:27,425 - trainer - INFO -     top_k_acc      : 0.5766414029160739
2022-04-15 23:02:27,425 - trainer - INFO -     val_loss       : 3.5065553188323975
2022-04-15 23:02:27,425 - trainer - INFO -     val_accuracy   : 0.4830729166666667
2022-04-15 23:02:27,425 - trainer - INFO -     val_top_k_acc  : 0.5559895833333334
2022-04-15 23:02:27,577 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch55.pth ...
2022-04-15 23:03:34,718 - trainer - INFO -     epoch          : 56
2022-04-15 23:03:34,719 - trainer - INFO -     loss           : 3.4859845136341296
2022-04-15 23:03:34,719 - trainer - INFO -     accuracy       : 0.5049786628733998
2022-04-15 23:03:34,719 - trainer - INFO -     top_k_acc      : 0.5857596906116642
2022-04-15 23:03:34,719 - trainer - INFO -     val_loss       : 3.419358412424723
2022-04-15 23:03:34,719 - trainer - INFO -     val_accuracy   : 0.5638020833333334
2022-04-15 23:03:34,719 - trainer - INFO -     val_top_k_acc  : 0.6328125
2022-04-15 23:03:34,871 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch56.pth ...
2022-04-15 23:03:35,019 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 23:04:42,443 - trainer - INFO -     epoch          : 57
2022-04-15 23:04:42,444 - trainer - INFO -     loss           : 3.4875115595365824
2022-04-15 23:04:42,444 - trainer - INFO -     accuracy       : 0.5034339438122333
2022-04-15 23:04:42,444 - trainer - INFO -     top_k_acc      : 0.5821257112375534
2022-04-15 23:04:42,444 - trainer - INFO -     val_loss       : 3.4147223631540933
2022-04-15 23:04:42,444 - trainer - INFO -     val_accuracy   : 0.5625
2022-04-15 23:04:42,444 - trainer - INFO -     val_top_k_acc  : 0.7174479166666666
2022-04-15 23:04:42,601 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch57.pth ...
2022-04-15 23:04:42,746 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 23:05:50,440 - trainer - INFO -     epoch          : 58
2022-04-15 23:05:50,440 - trainer - INFO -     loss           : 3.4894002864235327
2022-04-15 23:05:50,440 - trainer - INFO -     accuracy       : 0.501822546230441
2022-04-15 23:05:50,440 - trainer - INFO -     top_k_acc      : 0.5796752756045519
2022-04-15 23:05:50,441 - trainer - INFO -     val_loss       : 3.3477910359700522
2022-04-15 23:05:50,441 - trainer - INFO -     val_accuracy   : 0.64453125
2022-04-15 23:05:50,441 - trainer - INFO -     val_top_k_acc  : 0.71484375
2022-04-15 23:05:50,598 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch58.pth ...
2022-04-15 23:05:50,746 - trainer - INFO - Saving current best: model_best.pth ...
2022-04-15 23:06:57,301 - trainer - INFO -     epoch          : 59
2022-04-15 23:06:57,301 - trainer - INFO -     loss           : 3.4803863701067472
2022-04-15 23:06:57,301 - trainer - INFO -     accuracy       : 0.5078902916073968
2022-04-15 23:06:57,302 - trainer - INFO -     top_k_acc      : 0.595594772403983
2022-04-15 23:06:57,302 - trainer - INFO -     val_loss       : 3.643759806950887
2022-04-15 23:06:57,302 - trainer - INFO -     val_accuracy   : 0.3190104166666667
2022-04-15 23:06:57,302 - trainer - INFO -     val_top_k_acc  : 0.390625
2022-04-15 23:06:57,459 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch59.pth ...
2022-04-15 23:08:05,108 - trainer - INFO -     epoch          : 60
2022-04-15 23:08:05,109 - trainer - INFO -     loss           : 3.4808296655353748
2022-04-15 23:08:05,109 - trainer - INFO -     accuracy       : 0.5136802098150782
2022-04-15 23:08:05,109 - trainer - INFO -     top_k_acc      : 0.5884490576102418
2022-04-15 23:08:05,109 - trainer - INFO -     val_loss       : 3.5696451663970947
2022-04-15 23:08:05,109 - trainer - INFO -     val_accuracy   : 0.4856770833333333
2022-04-15 23:08:05,109 - trainer - INFO -     val_top_k_acc  : 0.7122395833333334
2022-04-15 23:08:05,261 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch60.pth ...
2022-04-15 23:09:12,919 - trainer - INFO -     epoch          : 61
2022-04-15 23:09:12,919 - trainer - INFO -     loss           : 3.486460070861013
2022-04-15 23:09:12,920 - trainer - INFO -     accuracy       : 0.5057454658605974
2022-04-15 23:09:12,920 - trainer - INFO -     top_k_acc      : 0.5831703413940256
2022-04-15 23:09:12,920 - trainer - INFO -     val_loss       : 3.5316739082336426
2022-04-15 23:09:12,920 - trainer - INFO -     val_accuracy   : 0.484375
2022-04-15 23:09:12,920 - trainer - INFO -     val_top_k_acc  : 0.5533854166666666
2022-04-15 23:09:13,084 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch61.pth ...
2022-04-15 23:10:20,170 - trainer - INFO -     epoch          : 62
2022-04-15 23:10:20,171 - trainer - INFO -     loss           : 3.482794159337094
2022-04-15 23:10:20,171 - trainer - INFO -     accuracy       : 0.5039118065433855
2022-04-15 23:10:20,171 - trainer - INFO -     top_k_acc      : 0.5848150782361309
2022-04-15 23:10:20,171 - trainer - INFO -     val_loss       : 3.4222254753112793
2022-04-15 23:10:20,171 - trainer - INFO -     val_accuracy   : 0.5690104166666666
2022-04-15 23:10:20,171 - trainer - INFO -     val_top_k_acc  : 0.6341145833333334
2022-04-15 23:10:20,331 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch62.pth ...
2022-04-15 23:11:27,799 - trainer - INFO -     epoch          : 63
2022-04-15 23:11:27,800 - trainer - INFO -     loss           : 3.480810617145739
2022-04-15 23:11:27,800 - trainer - INFO -     accuracy       : 0.5126189100284495
2022-04-15 23:11:27,800 - trainer - INFO -     top_k_acc      : 0.5908828236130867
2022-04-15 23:11:27,800 - trainer - INFO -     val_loss       : 3.382516860961914
2022-04-15 23:11:27,800 - trainer - INFO -     val_accuracy   : 0.65234375
2022-04-15 23:11:27,800 - trainer - INFO -     val_top_k_acc  : 0.71484375
2022-04-15 23:11:27,953 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch63.pth ...
2022-04-15 23:12:36,702 - trainer - INFO -     epoch          : 64
2022-04-15 23:12:36,702 - trainer - INFO -     loss           : 3.4767496460362484
2022-04-15 23:12:36,702 - trainer - INFO -     accuracy       : 0.520448079658606
2022-04-15 23:12:36,702 - trainer - INFO -     top_k_acc      : 0.593794452347084
2022-04-15 23:12:36,702 - trainer - INFO -     val_loss       : 3.479185104370117
2022-04-15 23:12:36,702 - trainer - INFO -     val_accuracy   : 0.48828125
2022-04-15 23:12:36,703 - trainer - INFO -     val_top_k_acc  : 0.7174479166666666
2022-04-15 23:12:36,855 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch64.pth ...
2022-04-15 23:13:46,325 - trainer - INFO -     epoch          : 65
2022-04-15 23:13:46,325 - trainer - INFO -     loss           : 3.4760834919778922
2022-04-15 23:13:46,325 - trainer - INFO -     accuracy       : 0.5144859086059744
2022-04-15 23:13:46,325 - trainer - INFO -     top_k_acc      : 0.595266936344239
2022-04-15 23:13:46,325 - trainer - INFO -     val_loss       : 3.564464251200358
2022-04-15 23:13:46,326 - trainer - INFO -     val_accuracy   : 0.4075520833333333
2022-04-15 23:13:46,326 - trainer - INFO -     val_top_k_acc  : 0.4713541666666667
2022-04-15 23:13:46,482 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch65.pth ...
2022-04-15 23:14:55,618 - trainer - INFO -     epoch          : 66
2022-04-15 23:14:55,618 - trainer - INFO -     loss           : 3.477303994329352
2022-04-15 23:14:55,618 - trainer - INFO -     accuracy       : 0.5190089349217639
2022-04-15 23:14:55,618 - trainer - INFO -     top_k_acc      : 0.5989009157183499
2022-04-15 23:14:55,618 - trainer - INFO -     val_loss       : 3.4779890378316245
2022-04-15 23:14:55,618 - trainer - INFO -     val_accuracy   : 0.4869791666666667
2022-04-15 23:14:55,619 - trainer - INFO -     val_top_k_acc  : 0.5572916666666666
2022-04-15 23:14:55,773 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch66.pth ...
2022-04-15 23:16:04,694 - trainer - INFO -     epoch          : 67
2022-04-15 23:16:04,694 - trainer - INFO -     loss           : 3.4781701815755746
2022-04-15 23:16:04,694 - trainer - INFO -     accuracy       : 0.51143536628734
2022-04-15 23:16:04,694 - trainer - INFO -     top_k_acc      : 0.5981452258179232
2022-04-15 23:16:04,694 - trainer - INFO -     val_loss       : 3.6365675926208496
2022-04-15 23:16:04,694 - trainer - INFO -     val_accuracy   : 0.32421875
2022-04-15 23:16:04,694 - trainer - INFO -     val_top_k_acc  : 0.4765625
2022-04-15 23:16:04,926 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch67.pth ...
2022-04-15 23:17:13,109 - trainer - INFO -     epoch          : 68
2022-04-15 23:17:13,109 - trainer - INFO -     loss           : 3.4756386781993664
2022-04-15 23:17:13,109 - trainer - INFO -     accuracy       : 0.514108063655761
2022-04-15 23:17:13,110 - trainer - INFO -     top_k_acc      : 0.5969116731863442
2022-04-15 23:17:13,110 - trainer - INFO -     val_loss       : 3.565504789352417
2022-04-15 23:17:13,110 - trainer - INFO -     val_accuracy   : 0.4036458333333333
2022-04-15 23:17:13,110 - trainer - INFO -     val_top_k_acc  : 0.5520833333333334
2022-04-15 23:17:13,269 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch68.pth ...
2022-04-15 23:18:22,155 - trainer - INFO -     epoch          : 69
2022-04-15 23:18:22,156 - trainer - INFO -     loss           : 3.4785334185550085
2022-04-15 23:18:22,156 - trainer - INFO -     accuracy       : 0.5141247332859175
2022-04-15 23:18:22,156 - trainer - INFO -     top_k_acc      : 0.5893381045519203
2022-04-15 23:18:22,156 - trainer - INFO -     val_loss       : 3.5629590352376304
2022-04-15 23:18:22,156 - trainer - INFO -     val_accuracy   : 0.4075520833333333
2022-04-15 23:18:22,156 - trainer - INFO -     val_top_k_acc  : 0.4713541666666667
2022-04-15 23:18:22,310 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch69.pth ...
2022-04-15 23:19:29,951 - trainer - INFO -     epoch          : 70
2022-04-15 23:19:29,951 - trainer - INFO -     loss           : 3.4700961614909924
2022-04-15 23:19:29,951 - trainer - INFO -     accuracy       : 0.5181698968705547
2022-04-15 23:19:29,951 - trainer - INFO -     top_k_acc      : 0.6001177987197724
2022-04-15 23:19:29,951 - trainer - INFO -     val_loss       : 3.477998733520508
2022-04-15 23:19:29,951 - trainer - INFO -     val_accuracy   : 0.4856770833333333
2022-04-15 23:19:29,951 - trainer - INFO -     val_top_k_acc  : 0.5546875
2022-04-15 23:19:30,114 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch70.pth ...
2022-04-15 23:20:38,975 - trainer - INFO -     epoch          : 71
2022-04-15 23:20:38,976 - trainer - INFO -     loss           : 3.4702934340426794
2022-04-15 23:20:38,976 - trainer - INFO -     accuracy       : 0.5252100373399715
2022-04-15 23:20:38,976 - trainer - INFO -     top_k_acc      : 0.5989175853485064
2022-04-15 23:20:38,976 - trainer - INFO -     val_loss       : 3.527770439783732
2022-04-15 23:20:38,976 - trainer - INFO -     val_accuracy   : 0.48828125
2022-04-15 23:20:38,976 - trainer - INFO -     val_top_k_acc  : 0.6432291666666666
2022-04-15 23:20:39,132 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch71.pth ...
2022-04-15 23:22:05,808 - trainer - INFO -     epoch          : 72
2022-04-15 23:22:05,809 - trainer - INFO -     loss           : 3.4737635160747327
2022-04-15 23:22:05,809 - trainer - INFO -     accuracy       : 0.5118965593883358
2022-04-15 23:22:05,809 - trainer - INFO -     top_k_acc      : 0.6065078236130867
2022-04-15 23:22:05,810 - trainer - INFO -     val_loss       : 3.508953809738159
2022-04-15 23:22:05,810 - trainer - INFO -     val_accuracy   : 0.4921875
2022-04-15 23:22:05,810 - trainer - INFO -     val_top_k_acc  : 0.6419270833333334
2022-04-15 23:22:05,976 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch72.pth ...
2022-04-15 23:24:09,403 - trainer - INFO -     epoch          : 73
2022-04-15 23:24:09,403 - trainer - INFO -     loss           : 3.46533203125
2022-04-15 23:24:09,404 - trainer - INFO -     accuracy       : 0.5223150782361309
2022-04-15 23:24:09,404 - trainer - INFO -     top_k_acc      : 0.602445990398293
2022-04-15 23:24:09,404 - trainer - INFO -     val_loss       : 3.4682953357696533
2022-04-15 23:24:09,404 - trainer - INFO -     val_accuracy   : 0.48828125
2022-04-15 23:24:09,404 - trainer - INFO -     val_top_k_acc  : 0.640625
2022-04-15 23:24:09,569 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch73.pth ...
2022-04-15 23:25:46,885 - trainer - INFO -     epoch          : 74
2022-04-15 23:25:46,886 - trainer - INFO -     loss           : 3.4657428390101384
2022-04-15 23:25:46,886 - trainer - INFO -     accuracy       : 0.5323557521337127
2022-04-15 23:25:46,886 - trainer - INFO -     top_k_acc      : 0.6011624288762447
2022-04-15 23:25:46,886 - trainer - INFO -     val_loss       : 3.3999598821004233
2022-04-15 23:25:46,886 - trainer - INFO -     val_accuracy   : 0.5768229166666666
2022-04-15 23:25:46,886 - trainer - INFO -     val_top_k_acc  : 0.640625
2022-04-15 23:25:47,039 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch74.pth ...
2022-04-15 23:27:19,844 - trainer - INFO -     epoch          : 75
2022-04-15 23:27:19,845 - trainer - INFO -     loss           : 3.4669091952474496
2022-04-15 23:27:19,845 - trainer - INFO -     accuracy       : 0.5258101440256046
2022-04-15 23:27:19,845 - trainer - INFO -     top_k_acc      : 0.598573079658606
2022-04-15 23:27:19,845 - trainer - INFO -     val_loss       : 3.5505717595418296
2022-04-15 23:27:19,845 - trainer - INFO -     val_accuracy   : 0.4934895833333333
2022-04-15 23:27:19,845 - trainer - INFO -     val_top_k_acc  : 0.55859375
2022-04-15 23:27:20,007 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch75.pth ...
2022-04-15 23:28:43,120 - trainer - INFO -     epoch          : 76
2022-04-15 23:28:43,120 - trainer - INFO -     loss           : 3.4707480606279875
2022-04-15 23:28:43,120 - trainer - INFO -     accuracy       : 0.5210815256045519
2022-04-15 23:28:43,120 - trainer - INFO -     top_k_acc      : 0.597272848506401
2022-04-15 23:28:43,120 - trainer - INFO -     val_loss       : 3.471916119257609
2022-04-15 23:28:43,121 - trainer - INFO -     val_accuracy   : 0.4895833333333333
2022-04-15 23:28:43,121 - trainer - INFO -     val_top_k_acc  : 0.6419270833333334
2022-04-15 23:28:43,293 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch76.pth ...
2022-04-15 23:29:57,292 - trainer - INFO -     epoch          : 77
2022-04-15 23:29:57,293 - trainer - INFO -     loss           : 3.4709298108753406
2022-04-15 23:29:57,293 - trainer - INFO -     accuracy       : 0.5186977684921764
2022-04-15 23:29:57,293 - trainer - INFO -     top_k_acc      : 0.5951446923897582
2022-04-15 23:29:57,293 - trainer - INFO -     val_loss       : 3.547306934992472
2022-04-15 23:29:57,294 - trainer - INFO -     val_accuracy   : 0.4127604166666667
2022-04-15 23:29:57,294 - trainer - INFO -     val_top_k_acc  : 0.5598958333333334
2022-04-15 23:29:57,464 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch77.pth ...
2022-04-15 23:31:08,441 - trainer - INFO -     epoch          : 78
2022-04-15 23:31:08,441 - trainer - INFO -     loss           : 3.474099585884496
2022-04-15 23:31:08,441 - trainer - INFO -     accuracy       : 0.5180476529160739
2022-04-15 23:31:08,442 - trainer - INFO -     top_k_acc      : 0.5960893047652916
2022-04-15 23:31:08,442 - trainer - INFO -     val_loss       : 3.4597437381744385
2022-04-15 23:31:08,442 - trainer - INFO -     val_accuracy   : 0.4921875
2022-04-15 23:31:08,442 - trainer - INFO -     val_top_k_acc  : 0.6393229166666666
2022-04-15 23:31:08,596 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch78.pth ...
2022-04-15 23:32:18,079 - trainer - INFO -     epoch          : 79
2022-04-15 23:32:18,080 - trainer - INFO -     loss           : 3.4680158088081763
2022-04-15 23:32:18,080 - trainer - INFO -     accuracy       : 0.5198813122332858
2022-04-15 23:32:18,080 - trainer - INFO -     top_k_acc      : 0.6016236219772404
2022-04-15 23:32:18,080 - trainer - INFO -     val_loss       : 3.549776474634806
2022-04-15 23:32:18,080 - trainer - INFO -     val_accuracy   : 0.4114583333333333
2022-04-15 23:32:18,080 - trainer - INFO -     val_top_k_acc  : 0.55859375
2022-04-15 23:32:18,236 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch79.pth ...
2022-04-15 23:33:26,465 - trainer - INFO -     epoch          : 80
2022-04-15 23:33:26,465 - trainer - INFO -     loss           : 3.464571137177317
2022-04-15 23:33:26,465 - trainer - INFO -     accuracy       : 0.5261879889758179
2022-04-15 23:33:26,465 - trainer - INFO -     top_k_acc      : 0.6126255778805121
2022-04-15 23:33:26,465 - trainer - INFO -     val_loss       : 3.4801458517710366
2022-04-15 23:33:26,465 - trainer - INFO -     val_accuracy   : 0.4947916666666667
2022-04-15 23:33:26,465 - trainer - INFO -     val_top_k_acc  : 0.55859375
2022-04-15 23:33:26,625 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch80.pth ...
2022-04-15 23:34:35,406 - trainer - INFO -     epoch          : 81
2022-04-15 23:34:35,406 - trainer - INFO -     loss           : 3.457594055878489
2022-04-15 23:34:35,406 - trainer - INFO -     accuracy       : 0.5392625355618776
2022-04-15 23:34:35,406 - trainer - INFO -     top_k_acc      : 0.6124033161450925
2022-04-15 23:34:35,406 - trainer - INFO -     val_loss       : 3.4768994649251304
2022-04-15 23:34:35,406 - trainer - INFO -     val_accuracy   : 0.4947916666666667
2022-04-15 23:34:35,407 - trainer - INFO -     val_top_k_acc  : 0.5611979166666666
2022-04-15 23:34:35,569 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch81.pth ...
2022-04-15 23:35:43,997 - trainer - INFO -     epoch          : 82
2022-04-15 23:35:43,998 - trainer - INFO -     loss           : 3.463929715909456
2022-04-15 23:35:43,998 - trainer - INFO -     accuracy       : 0.526426920341394
2022-04-15 23:35:43,998 - trainer - INFO -     top_k_acc      : 0.604279649715505
2022-04-15 23:35:43,998 - trainer - INFO -     val_loss       : 3.618752638498942
2022-04-15 23:35:43,998 - trainer - INFO -     val_accuracy   : 0.4114583333333333
2022-04-15 23:35:43,998 - trainer - INFO -     val_top_k_acc  : 0.48046875
2022-04-15 23:35:44,152 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch82.pth ...
2022-04-15 23:36:54,098 - trainer - INFO -     epoch          : 83
2022-04-15 23:36:54,099 - trainer - INFO -     loss           : 3.4636938195479545
2022-04-15 23:36:54,099 - trainer - INFO -     accuracy       : 0.5315833926031295
2022-04-15 23:36:54,099 - trainer - INFO -     top_k_acc      : 0.608819345661451
2022-04-15 23:36:54,099 - trainer - INFO -     val_loss       : 3.615354537963867
2022-04-15 23:36:54,099 - trainer - INFO -     val_accuracy   : 0.3294270833333333
2022-04-15 23:36:54,099 - trainer - INFO -     val_top_k_acc  : 0.48046875
2022-04-15 23:36:54,252 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch83.pth ...
2022-04-15 23:38:02,178 - trainer - INFO -     epoch          : 84
2022-04-15 23:38:02,179 - trainer - INFO -     loss           : 3.4630014896392822
2022-04-15 23:38:02,179 - trainer - INFO -     accuracy       : 0.5247821834992887
2022-04-15 23:38:02,179 - trainer - INFO -     top_k_acc      : 0.6139091394025605
2022-04-15 23:38:02,179 - trainer - INFO -     val_loss       : 3.555921792984009
2022-04-15 23:38:02,179 - trainer - INFO -     val_accuracy   : 0.4140625
2022-04-15 23:38:02,179 - trainer - INFO -     val_top_k_acc  : 0.4817708333333333
2022-04-15 23:38:02,340 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch84.pth ...
2022-04-15 23:39:11,252 - trainer - INFO -     epoch          : 85
2022-04-15 23:39:11,253 - trainer - INFO -     loss           : 3.4608769542292546
2022-04-15 23:39:11,253 - trainer - INFO -     accuracy       : 0.536673186344239
2022-04-15 23:39:11,253 - trainer - INFO -     top_k_acc      : 0.6110308499288762
2022-04-15 23:39:11,253 - trainer - INFO -     val_loss       : 3.4773417313893638
2022-04-15 23:39:11,253 - trainer - INFO -     val_accuracy   : 0.4934895833333333
2022-04-15 23:39:11,253 - trainer - INFO -     val_top_k_acc  : 0.5611979166666666
2022-04-15 23:39:11,407 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch85.pth ...
2022-04-15 23:40:22,709 - trainer - INFO -     epoch          : 86
2022-04-15 23:40:22,710 - trainer - INFO -     loss           : 3.4634506953390023
2022-04-15 23:40:22,710 - trainer - INFO -     accuracy       : 0.5295108019203414
2022-04-15 23:40:22,710 - trainer - INFO -     top_k_acc      : 0.6016569612375534
2022-04-15 23:40:22,710 - trainer - INFO -     val_loss       : 3.5460498332977295
2022-04-15 23:40:22,710 - trainer - INFO -     val_accuracy   : 0.5
2022-04-15 23:40:22,710 - trainer - INFO -     val_top_k_acc  : 0.5677083333333334
2022-04-15 23:40:22,879 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch86.pth ...
2022-04-15 23:41:31,015 - trainer - INFO -     epoch          : 87
2022-04-15 23:41:31,016 - trainer - INFO -     loss           : 3.457900649622867
2022-04-15 23:41:31,016 - trainer - INFO -     accuracy       : 0.5329558588193457
2022-04-15 23:41:31,016 - trainer - INFO -     top_k_acc      : 0.6120421408250355
2022-04-15 23:41:31,016 - trainer - INFO -     val_loss       : 3.4762160778045654
2022-04-15 23:41:31,016 - trainer - INFO -     val_accuracy   : 0.4934895833333333
2022-04-15 23:41:31,016 - trainer - INFO -     val_top_k_acc  : 0.5625
2022-04-15 23:41:31,175 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch87.pth ...
2022-04-15 23:42:38,509 - trainer - INFO -     epoch          : 88
2022-04-15 23:42:38,509 - trainer - INFO -     loss           : 3.4590369400225187
2022-04-15 23:42:38,509 - trainer - INFO -     accuracy       : 0.5332781383357041
2022-04-15 23:42:38,509 - trainer - INFO -     top_k_acc      : 0.6092471995021337
2022-04-15 23:42:38,509 - trainer - INFO -     val_loss       : 3.5506877104441323
2022-04-15 23:42:38,510 - trainer - INFO -     val_accuracy   : 0.4153645833333333
2022-04-15 23:42:38,510 - trainer - INFO -     val_top_k_acc  : 0.5651041666666666
2022-04-15 23:42:38,666 - trainer - INFO - Saving checkpoint: saved/models/kernel_generator/0415_215735/checkpoint-epoch88.pth ...
2022-04-15 23:43:46,674 - trainer - INFO -     epoch          : 89
2022-04-15 23:43:46,674 - trainer - INFO -     loss           : 3.4627557679226526
2022-04-15 23:43:46,675 - trainer - INFO -     accuracy       : 0.5309999555476529
2022-04-15 23:43:46,675 - trainer - INFO -     top_k_acc      : 0.6047575124466572
2022-04-15 23:43:46,675 - trainer - INFO -     val_loss       : 3.5465051333109536
2022-04-15 23:43:46,675 - trainer - INFO -     val_accuracy   : 0.4140625
2022-04-15 23:43:46,675 - trainer - INFO -     val_top_k_acc  : 0.6471354166666666
2022-04-15 23:43:46,675 - trainer - INFO - Validation performance didn't improve for 30 epochs. Training stops.
2022-04-15 23:58:40,185 - test - INFO - kernel_extract_network(
  (encoder): kernel_generator(
    (basic_block): Sequential()
    (chain0): chain_process(
      (seq): Sequential(
        (0): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (2): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(27, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(81, 81, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (3): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(81, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(81, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(81, 243, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(81, 243, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(243, 243, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(243, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain1): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (2): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(27, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(27, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(81, 81, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain2): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
          (1): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(9, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(27, 27, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain3): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (3): Sequential(
          (0): Sequential(
            (0): Bottleneck(
              (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (conv3): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn3): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (downsample): Sequential(
                (0): Conv2d(3, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): convBlock(
              (conv): Conv2d(9, 9, kernel_size=(3, 3), stride=(3, 3), bias=False)
              (bn): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (dropout): Dropout2d(p=0.5, inplace=False)
            )
          )
        )
      )
    )
    (chain4): chain_process(
      (seq): Sequential(
        (0): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (1): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (2): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (3): downSample(
          (downsample): MaxPool2d(kernel_size=3, stride=3, padding=1, dilation=1, ceil_mode=False)
        )
        (4): Sequential()
      )
    )
    (oneSizeConv): oneSizeConv(
      (CBR): convBlock(
        (conv): Conv2d(363, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (dropout): Dropout2d(p=0.5, inplace=False)
      )
    )
  )
  (decoder): classify_decoder(
    (CBR): convBlock(
      (conv): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
      (dropout): Dropout2d(p=0.5, inplace=False)
    )
    (MLP): MLP(
      (inp): Linear(in_features=127, out_features=64, bias=True)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): LeakyReLU(negative_slope=0.01)
      (hidden): Linear(in_features=64, out_features=50, bias=True)
      (bn2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): LeakyReLU(negative_slope=0.01)
      (sftmax): Softmax(dim=1)
    )
  )
)
2022-04-15 23:58:40,192 - test - INFO - Loading checkpoint: saved/models/kernel_generator/0415_215735/model_best.pth ...
2022-04-16 00:00:28,843 - test - INFO - {'loss': 3.4319873757889927, 'accuracy': 0.5500871924045727, 'top_k_acc': 0.6153846153846154}
